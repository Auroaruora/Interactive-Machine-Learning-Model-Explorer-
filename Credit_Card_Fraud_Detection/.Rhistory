library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
#print(credit_predict, n = 100)
#levels(credit$Status)
#levels(credit_predict)
#length(credit$Status)
#length(credit_predict_fact)
set.seed(34567)
split <- initial_split(credit, prop = .7, strata = Status)  # 70%-%30 split
credit_train <- training(split)
credit_test <- testing(split)
resample <- trainControl(method = "boot", number = 15, classProbs = TRUE, summaryFunction = twoClassSummary)  # bootstrap option
## Creating grid of hyperparameter values
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
trellis.par.set(caretTheme()) # optional
plot(dt_fit, metric = "ROC")
# 0.01 is the best
## Fitting a final model with the optimal hyperparameter values
fitControl_final <- trainControl(method = "none", classProbs = TRUE, summaryFunction = twoClassSummary)   # no resampling applies to the data
dt_final <- train(Status ~.,
data = credit_train,
method = "rpart",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(cp = 0.01))
# Making predictions
dt_pred_train <- predict(dt_final, newdata = credit_train)
dt_pred_test <- predict(dt_final, newdata = credit_test)
credit_test_student = subset(x=credit_test, Student=="Yes")
credit_test_not_student = subset(x=credit_test, Student=="No")
credit_test_student_pred = predict(dt_final, newdata = credit_test_student)
credit_test_not_student_pred = predict(dt_final, newdata = credit_test_not_student)
library(readr)
library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
#print(credit_predict, n = 100)
#levels(credit$Status)
#levels(credit_predict)
#length(credit$Status)
#length(credit_predict_fact)
set.seed(34567)
split <- initial_split(credit, prop = .7, strata = Status)  # 70%-%30 split
credit_train <- training(split)
credit_test <- testing(split)
resample <- trainControl(method = "boot", number = 15, classProbs = TRUE, summaryFunction = twoClassSummary)  # bootstrap option
## Creating grid of hyperparameter values
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
trellis.par.set(caretTheme()) # optional
plot(dt_fit, metric = "ROC")
# 0.01 is the best
## Fitting a final model with the optimal hyperparameter values
fitControl_final <- trainControl(method = "none", classProbs = TRUE, summaryFunction = twoClassSummary)   # no resampling applies to the data
dt_final <- train(Status ~.,
data = credit_train,
method = "rpart",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(cp = 0.2))
# Making predictions
dt_pred_train <- predict(dt_final, newdata = credit_train)
dt_pred_test <- predict(dt_final, newdata = credit_test)
credit_test_student = subset(x=credit_test, Student=="Yes")
credit_test_not_student = subset(x=credit_test, Student=="No")
credit_test_student_pred = predict(dt_final, newdata = credit_test_student)
credit_test_not_student_pred = predict(dt_final, newdata = credit_test_not_student)
confusionMatrix(reference=credit$Status, data=credit_predict_fact)
confusionMatrix(reference=credit$Status, data=credit_predict_fact)
confusionMatrix(reference=credit_train$Status, data=dt_pred_train)
library(readr)
library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
#print(credit_predict, n = 100)
#levels(credit$Status)
#levels(credit_predict)
#length(credit$Status)
#length(credit_predict_fact)
set.seed(1)
split <- initial_split(credit, prop = .7, strata = Status)  # 70%-%30 split
credit_train <- training(split)
credit_test <- testing(split)
resample <- trainControl(method = "boot", number = 15, classProbs = TRUE, summaryFunction = twoClassSummary)  # bootstrap option
## Creating grid of hyperparameter values
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
trellis.par.set(caretTheme()) # optional
plot(dt_fit, metric = "ROC")
# 0.01 is the best
## Fitting a final model with the optimal hyperparameter values
fitControl_final <- trainControl(method = "none", classProbs = TRUE, summaryFunction = twoClassSummary)   # no resampling applies to the data
dt_final <- train(Status ~.,
data = credit_train,
method = "rpart",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(cp = 0.2))
# Making predictions
dt_pred_train <- predict(dt_final, newdata = credit_train)
dt_pred_test <- predict(dt_final, newdata = credit_test)
credit_test_student = subset(x=credit_test, Student=="Yes")
credit_test_not_student = subset(x=credit_test, Student=="No")
credit_test_student_pred = predict(dt_final, newdata = credit_test_student)
credit_test_not_student_pred = predict(dt_final, newdata = credit_test_not_student)
confusionMatrix(reference=credit_train$Status, data=dt_pred_train)
library(readr)
library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
#print(credit_predict, n = 100)
#levels(credit$Status)
#levels(credit_predict)
#length(credit$Status)
#length(credit_predict_fact)
set.seed(1)
split <- initial_split(credit, prop = .7, strata = Status)  # 70%-%30 split
credit_train <- training(split)
credit_test <- testing(split)
resample <- trainControl(method = "boot", number = 15, classProbs = TRUE, summaryFunction = twoClassSummary)  # bootstrap option
## Creating grid of hyperparameter values
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
trellis.par.set(caretTheme()) # optional
plot(dt_fit, metric = "ROC")
# 0.01 is the best
## Fitting a final model with the optimal hyperparameter values
fitControl_final <- trainControl(method = "none", classProbs = TRUE, summaryFunction = twoClassSummary)   # no resampling applies to the data
dt_final <- train(Status ~.,
data = credit_train,
method = "rpart",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(cp = 0.01))
# Making predictions
dt_pred_train <- predict(dt_final, newdata = credit_train)
dt_pred_test <- predict(dt_final, newdata = credit_test)
credit_test_student = subset(x=credit_test, Student=="Yes")
credit_test_not_student = subset(x=credit_test, Student=="No")
credit_test_student_pred = predict(dt_final, newdata = credit_test_student)
credit_test_not_student_pred = predict(dt_final, newdata = credit_test_not_student)
confusionMatrix(reference=credit_train$Status, data=dt_pred_train)
library(readr)
library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
#print(credit_predict, n = 100)
#levels(credit$Status)
#levels(credit_predict)
#length(credit$Status)
#length(credit_predict_fact)
set.seed(12345)
split <- initial_split(credit, prop = .7, strata = Status)  # 70%-%30 split
credit_train <- training(split)
credit_test <- testing(split)
resample <- trainControl(method = "boot", number = 15, classProbs = TRUE, summaryFunction = twoClassSummary)  # bootstrap option
## Creating grid of hyperparameter values
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
trellis.par.set(caretTheme()) # optional
plot(dt_fit, metric = "ROC")
# 0.01 is the best
## Fitting a final model with the optimal hyperparameter values
fitControl_final <- trainControl(method = "none", classProbs = TRUE, summaryFunction = twoClassSummary)   # no resampling applies to the data
dt_final <- train(Status ~.,
data = credit_train,
method = "rpart",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(cp = 0.01))
# Making predictions
dt_pred_train <- predict(dt_final, newdata = credit_train)
dt_pred_test <- predict(dt_final, newdata = credit_test)
credit_test_student = subset(x=credit_test, Student=="Yes")
credit_test_not_student = subset(x=credit_test, Student=="No")
credit_test_student_pred = predict(dt_final, newdata = credit_test_student)
credit_test_not_student_pred = predict(dt_final, newdata = credit_test_not_student)
library(readr)
library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
#print(credit_predict, n = 100)
#levels(credit$Status)
#levels(credit_predict)
#length(credit$Status)
#length(credit_predict_fact)
set.seed(11111)
split <- initial_split(credit, prop = .7, strata = Status)  # 70%-%30 split
credit_train <- training(split)
credit_test <- testing(split)
resample <- trainControl(method = "boot", number = 15, classProbs = TRUE, summaryFunction = twoClassSummary)  # bootstrap option
## Creating grid of hyperparameter values
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
trellis.par.set(caretTheme()) # optional
plot(dt_fit, metric = "ROC")
# 0.01 is the best
## Fitting a final model with the optimal hyperparameter values
fitControl_final <- trainControl(method = "none", classProbs = TRUE, summaryFunction = twoClassSummary)   # no resampling applies to the data
dt_final <- train(Status ~.,
data = credit_train,
method = "rpart",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(cp = 0.01))
# Making predictions
dt_pred_train <- predict(dt_final, newdata = credit_train)
dt_pred_test <- predict(dt_final, newdata = credit_test)
credit_test_student = subset(x=credit_test, Student=="Yes")
credit_test_not_student = subset(x=credit_test, Student=="No")
credit_test_student_pred = predict(dt_final, newdata = credit_test_student)
credit_test_not_student_pred = predict(dt_final, newdata = credit_test_not_student)
confusionMatrix(reference=credit_train$Status, data=dt_pred_train)
library(readr)
library(caret)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
Car_seats <- read_csv("C:\\Users\\mjstr\\Desktop\\Columbia Sem 2!\\4 - Applied ML (AML)\\Car_seats.csv")
nearZeroVar(Car_seats, saveMetrics = TRUE)
colSums(is.na(Car_seats))
head(Car_seats)
turn_to_num <- function(df, ordered_vec, old_col_name, new_col_name){
# note - you have to manually assign new df to the result
df[[new_col_name]] = as.numeric(factor(x=df[[old_col_name]], labels=c(1:length(ordered_vec)), levels = ordered_vec, ordered=TRUE))
return(df)
}
mean_na <- function(df, col_name, round_res = FALSE){
if (round_res) {
df[[col_name]][is.na(df[[col_name]])] = round(mean(df[[col_name]], na.rm = TRUE))
} else {
df[[col_name]][is.na(df[[col_name]])] = mean(df[[col_name]], na.rm = TRUE)
}
return(df)
}
# put in mean value for all "na" in the columns Age and Price
Car_seats = mean_na(Car_seats, "Age")
Car_seats = mean_na(Car_seats, "Price")
colSums(is.na(Car_seats))
# Normalize/Standardize all numeric features
Car_seats = Car_seats %>% mutate_at(c(2,3,4,6), funs(c(scale(.))))
# Fit the Sales to more or less a normal distribution
hist(Car_seats$Sales)
#it's already normal, so no math will be done
#Convert qualitative features to numeric ones
head(Car_seats)
unique(Car_seats$ShelveLoc)
ShelveLoc_vec = c("Bad", "Medium", "Good")
Car_seats = turn_to_num(Car_seats, ShelveLoc_vec, "ShelveLoc", "ShelveLoc")
yn_vec = c("No", "Yes")
Car_seats = turn_to_num(Car_seats, yn_vec, "Urban", "Urban")
Car_seats = turn_to_num(Car_seats, yn_vec, "US", "US")
# split dataset, 75-25%, systematically by order given
set.seed(1)
idx <- seq(from=floor(runif(1, 1, 5)), to = 400, by = 4)
Car_seats_test <- Car_seats[idx, ]
Car_seats_train <- Car_seats[-idx, ]
# start on fitting model, part 4
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
resample <- trainControl(method = "repeatedcv",
number = 5,
repeats = 4,
summaryFunction = defaultSummary,
search = "grid")
dt_fit <- train(Sales ~ .,
data = Car_seats_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "RMSE")
# Plotting results
ggplot(dt_fit)
library(readr)
library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
confusionMatrix(reference=credit$Status, data=credit_predict_fact)
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
library(readr)
library(caret)
library(parsnip)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(yardstick)
credit <- read_csv("C:/Users/mjstr/Desktop/Columbia Sem 2!/4 - Applied ML (AML)/credit.csv")
credit$Status=factor(x=credit$Status, levels = c('bad', 'good'),  ordered=TRUE)
nearZeroVar(credit, saveMetrics = TRUE)
colSums(is.na(credit))
head(credit)
dt_reg_fit <-  decision_tree(mode='classification')%>%
set_mode("classification") %>%
set_engine("rpart") %>%
fit(Status ~ ., data = credit)
credit_predict <- predict(dt_reg_fit, new_data = credit)
#unique(data.frame(credit$Status))
#unique(data.frame(credit_predict))
credit_predict_fact = factor(x=credit_predict$.pred_class, levels = c('bad', 'good'))
#print(credit_predict, n = 100)
#levels(credit$Status)
#levels(credit_predict)
#length(credit$Status)
#length(credit_predict_fact)
set.seed(11111)
split <- initial_split(credit, prop = .7, strata = Status)  # 70%-%30 split
credit_train <- training(split)
credit_test <- testing(split)
resample <- trainControl(method = "boot", number = 15, classProbs = TRUE, summaryFunction = twoClassSummary)  # bootstrap option
## Creating grid of hyperparameter values
hyper_grid <- expand.grid(cp = c(0.001, 0.01, 0.05, 0.1, 0.2))
## Tuning Hyperparameters
dt_fit <- train(Status ~ .,
data = credit_train,
method = "rpart",
trControl = resample,
tuneGrid = hyper_grid,
metric = "ROC")
trellis.par.set(caretTheme()) # optional
plot(dt_fit, metric = "Spec")
plot(dt_fit, metric = "Sens")
fitControl_final <- trainControl(method = "none", classProbs = TRUE, summaryFunction = twoClassSummary)   # no resampling applies to the data
dt_final <- train(Status ~.,
data = credit_train,
method = "rpart",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(cp = 0.01))
# Making predictions
dt_pred_train <- predict(dt_final, newdata = credit_train)
dt_pred_test <- predict(dt_final, newdata = credit_test)
confusionMatrix(reference=credit_train$Status, data=dt_pred_train)
confusionMatrix(reference=credit_test$Status, data=dt_pred_test)
credit_test_student = subset(x=credit_test, Student=="Yes")
credit_test_not_student = subset(x=credit_test, Student=="No")
credit_test_student_pred = predict(dt_final, newdata = credit_test_student)
credit_test_not_student_pred = predict(dt_final, newdata = credit_test_not_student)
confusionMatrix(reference=credit_test_student$Status, data=credit_test_student_pred)
confusionMatrix(reference=credit_test_not_student$Status, data=credit_test_not_student_pred)
shiny::runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
shiny::runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
runApp('C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection')
pwd()
cwd()
cwd
setwd("C:/Users/mjstr/Desktop/Git Repository Final Python Project/FinalAML/Credit_Card_Fraud_Detection")
runApp('./')
runApp('./')
shiny::runApp()
