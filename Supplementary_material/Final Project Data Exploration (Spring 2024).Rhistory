max_depth = c(4, 6, 8, 10),
eta = c(0.05, 0.1, 0.2, 0.3),
min_child_weight = c(5, 10, 15),
subsample = c(0.4, 0.6),
gamma = 0,
colsample_bytree = 1)
xg_fit <- train(V16 ~ .,
data = data_train_no_na,
method = "xgbTree",
trControl = resample,
tuneGrid = hyper_grid_xg,
metric = "ROC",
verbosity = 0)
hyper_grid_xg <- expand.grid(nrounds = c(25, 50, 75),
max_depth = c(4, 6, 8),
eta = c(0.05, 0.1, 0.2, 0.3),
min_child_weight = c(5, 10, 15),
subsample = c(0.4, 0.6),
gamma = 0,
colsample_bytree = 1)
hyper_grid_xg <- expand.grid(nrounds = c(25, 50, 75),
max_depth = c(4, 6, 8),
eta = c(0.05, 0.1, 0.2, 0.3),
min_child_weight = c(5, 10, 15),
subsample = c(0.4, 0.6),
gamma = 0,
colsample_bytree = 1)
xg_fit <- train(V16 ~ .,
data = data_train_no_na,
method = "xgbTree",
trControl = resample,
tuneGrid = hyper_grid_xg,
metric = "ROC",
verbosity = 0)
plot(xg_fit)
ggplot(xg_fit)
plot(xg_fit, metric = "ROC", plotType = "level")
plot(rf_fit, metric = "ROC", plotType = "level")
plot(rf_fit, metric = "ROC")
plot(rf_fit)
ggplot(rf_fit)
plot(rf_fit)
plot(xg_fit)
RF <- train(V16_X. ~ .,
data = transformed_train,
method = "ranger",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(mtry = 15,
min.node.size = 3,
splitrule = "extratrees"),
num.trees = 300,
importance = "impurity")
XG <- train(V16_X. ~ .,
data = transformed_train,
method = "xgbTree",
verbose = FALSE,
verbosity = 0,
trControl = resample,
tuneGrid = hyper_grid_xg,
metric = "ROC")
XGB <- train(V16_X. ~ .,
data = transformed_train,
method = "xgbTree",
verbose = FALSE,
verbosity = 0,
trControl = resample,
tuneGrid = hyper_grid_xg,
metric = "ROC")
RF_pred_train <- predict(RF, newdata = transformed_train)
RF_train_results <- confusionMatrix(transformed_train$V16_X., RF_pred_train)
RF_Kappa <- RF_train_results$overall["Kappa"]
XGB_pred_train <- predict(XGB, newdata = transformed_train)
XGB_train_results <- confusionMatrix(transformed_train$V16_X., XGB_pred_train)
XGB_Kappa <- XGB_train_results$overall["Kappa"]
XGB_prediction <- predict(XGB, newdata = transformed_test, type = "prob")[,"X1"]
XBG_prediction
XGB_prediction <- predict(XGB, newdata = transformed_test, type = "prob")[,"X1"]
XBG_prediction
XGB_prediction
vip(XGB)
vip(RF)
vip(RF, geom = "point")
vip(RF)
vip(XGB)
SVM_Linear <- train(V16_X. ~ .,
data = transformed_train,
method = "svmLinear",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_Lin,
metric = "ROC")
#SVM
SVMGrid_Lin <- expand.grid(C = c(0.01, 0.1, 1, 10))
SVM_Linear <- train(V16_X. ~ .,
data = transformed_train,
method = "svmLinear",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_Lin,
metric = "ROC")
SVMGrid_Poly <- expand.grid(C = c(0.01, 0.1, 1, 10),
degree = c(2, 3),
scale = 1)
SVMGrid_RBF <- expand.grid (sigma = c(0.01, 0.1, 1, 10),
C = c(0.01, 0.1, 1, 10))
#SVM
SVMGrid_Lin <- expand.grid(C = c(0.01, 0.1, 1, 10))
SVMGrid_Poly <- expand.grid(C = c(0.01, 0.1, 1, 10),
degree = c(2, 3),
scale = 1)
SVMGrid_RBF <- expand.grid (sigma = c(0.01, 0.1, 1, 10),
C = c(0.01, 0.1, 1, 10))
SVM_Poly <- train(Attrition ~ .,
data = transformed_train,
method = "svmPoly",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_Poly,
metric = "ROC")
SVM_Poly <- train(V16_X. ~ .,
data = transformed_train,
method = "svmPoly",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_Poly,
metric = "ROC")
SVM_RBF <- train(V16_X. ~ .,
data = transformed_train,
method = "svmRadial",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_RBF,
metric = "ROC")
resamps <- resamples(list(SVM_Linear = SVM_Linear,
SVM_Poly = SVM_Poly,
SVM_RBF = SVM_RBF))
summary(resamps)
bwplot(resamps, layout = c(3, 1))
dotplot(resamps, metric = "ROC")
SVM_pred_train <- predict.train(SVM_Poly, newdata = data_train %>% select(-V16_X.))
SVM_pred_train <- predict.train(SVM_Poly, newdata = data_train)
SVM_Poly
# R Lab 9 - 03/28/24
# Stacked Models & Interpretable ML in R
## Libraries
library(caret)
library(tidymodels)
library(tidyverse)
library(vip)   # first install the "vip" package you haven't done it before
## Caret package
## Data Preparation: Data Splitting & Pre-processing
set.seed(1)
attrition <- attrition
attrition$Attrition <- factor(attrition$Attrition, levels = c("Yes", "No"))
index <- createDataPartition(attrition$Attrition, p = 0.75, list = FALSE)  # 75%-25% split
attrition_train <- attrition[index, ]
attrition_test <- attrition[-index, ]
blueprint <- recipe(Attrition ~ ., data = attrition_train) %>%
step_string2factor(all_nominal_predictors()) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
blueprint_prep <- prep(blueprint, training = attrition_train)
attrition_train <- bake(blueprint_prep, new_data = attrition_train)
attrition_test <- bake(blueprint_prep, new_data = attrition_test)
## Stacked Models (Weighted Ensemble Model)
# Base Learners
set.seed(1)
fitControl_final <- trainControl(method = "none", classProbs = TRUE)
# Random Forest (RF)
RF <- train(Attrition ~ .,
data = attrition_train,
method = "ranger",
trControl = fitControl_final,
metric = "ROC",
verbose = FALSE,
tuneGrid = data.frame(mtry = 13,
min.node.size = 7,
splitrule = "extratrees"),
num.trees = 300,
importance = "impurity")
RF_pred_train <- predict(RF, newdata = attrition_train)
RF_train_results <- confusionMatrix(attrition_train$Attrition, RF_pred_train)
RF_Kappa <- RF_train_results$overall["Kappa"]
# Support Vector Machine (SVM)
SVM <- train(Attrition ~ .,
data = attrition_train,
method = "svmLinear",
trControl = fitControl_final,
verbose = FALSE,
tuneGrid = data.frame(C = 0.1),
metric = "ROC",
importance = TRUE)
SVM_pred_train <- predict.train(SVM, newdata = attrition_train %>% select(-Attrition))
SVM_pred_train <- predict.train(SVM, newdata = attrition_train)
SVM_pred_train <- predict.train(SVM_Poly, newdata = transformed_train)
SVM_pred_train <- predict.train(SVM_Poly, newdata = transformed_train)
SVM_train_results <- confusionMatrix(transformed_train$V16_X., SVM_pred_train)
SVM_Kappa <- SVM_train_results$overall["Kappa"]
SVM_prediction <- predict(SVM_Poly, newdata = transformed_test, type = "prob")[,"X1"]
transformed_test$V16_X.
Weights <- c((RF_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(SVM_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(XGB_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2))
super_learner <- function(M1, M2, M3, W) {
weighted_average <- t(W*t(cbind(M1, M2, M3))) %>% apply(1, sum)
final_prediction <- ifelse(weighted_average > 0.5, "Yes", "No") %>% factor(levels = c("Yes", "No"))
return(final_prediction)
}
SP_prediction <- super_learner(RF_prediction, SVM_prediction, XGB_prediction, Weights)
SP_prediction
SP_results <- confusionMatrix(transformed_train$V16_X., SP_prediction)
final_prediction <- ifelse(weighted_average > 0.5, "X1", "X0") %>% factor(levels = c("X1", "X0"))
super_learner <- function(M1, M2, M3, W) {
weighted_average <- t(W*t(cbind(M1, M2, M3))) %>% apply(1, sum)
final_prediction <- ifelse(weighted_average > 0.5, "X1", "X0") %>% factor(levels = c("X1", "X0"))
return(final_prediction)
}
SP_prediction <- super_learner(RF_prediction, SVM_prediction, XGB_prediction, Weights)
SP_results <- confusionMatrix(transformed_train$V16_X., SP_prediction)
index <- createDataPartition(attrition$Attrition, p = 0.75, list = FALSE)  # 75%-25% split
attrition_train <- attrition[index, ]
attrition_test <- attrition[-index, ]
blueprint <- recipe(Attrition ~ ., data = attrition_train) %>%
step_string2factor(all_nominal_predictors()) %>%
step_center(all_numeric_predictors()) %>%
step_scale(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
blueprint_prep <- prep(blueprint, training = attrition_train)
attrition_train <- bake(blueprint_prep, new_data = attrition_train)
attrition_test <- bake(blueprint_prep, new_data = attrition_test)
## Stacked Models (Weighted Ensemble Model)
# Base Learners
set.seed(1)
fitControl_final <- trainControl(method = "none", classProbs = TRUE)
# Random Forest (RF)
RF <- train(Attrition ~ .,
data = attrition_train,
method = "ranger",
trControl = fitControl_final,
metric = "ROC",
verbose = FALSE,
tuneGrid = data.frame(mtry = 13,
min.node.size = 7,
splitrule = "extratrees"),
num.trees = 300,
importance = "impurity")
RF_pred_train <- predict(RF, newdata = attrition_train)
RF_train_results <- confusionMatrix(attrition_train$Attrition, RF_pred_train)
RF_Kappa <- RF_train_results$overall["Kappa"]
# Support Vector Machine (SVM)
SVM <- train(Attrition ~ .,
data = attrition_train,
method = "svmLinear",
trControl = fitControl_final,
verbose = FALSE,
tuneGrid = data.frame(C = 0.1),
metric = "ROC",
importance = TRUE)
SVM_pred_train <- predict.train(SVM, newdata = attrition_train %>% select(-Attrition))
SVM_train_results <- confusionMatrix(attrition_train$Attrition, SVM_pred_train)
SVM_Kappa <- SVM_train_results$overall["Kappa"]
# Extreme Gradient Boosting Machine (XGBoost)
XGB <- train(Attrition ~ .,
data = attrition_train,
method = "xgbTree",
verbose = FALSE,
trControl = fitControl_final,
tuneGrid = data.frame(nrounds = 150,
max_depth = 4,
eta = 0.2,
min_child_weight = 6,
subsample = 0.7,
gamma = 0,
colsample_bytree = 1),
metric = "ROC",
importance = TRUE)
XGB_pred_train <- predict(XGB, newdata = attrition_train)
XGB_train_results <- confusionMatrix(attrition_train$Attrition, XGB_pred_train)
XGB_Kappa <- XGB_train_results$overall["Kappa"]
# Super Learner (SP)
# Weights
Weights <- c((RF_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(SVM_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(XGB_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2))
super_learner <- function(M1, M2, M3, W) {
weighted_average <- t(W*t(cbind(M1, M2, M3))) %>% apply(1, sum)
final_prediction <- ifelse(weighted_average > 0.5, "Yes", "No") %>% factor(levels = c("Yes", "No"))
return(final_prediction)
}
# Making predictions
RF_prediction <- predict(RF, newdata = attrition_test, type = "prob")[, "Yes"]
SVM_prediction <- predict.train(SVM, newdata = attrition_test %>% select(-Attrition), type = "prob")[, "Yes"]
XGB_prediction <- predict(XGB, newdata = attrition_test, type = "prob")[, "Yes"]
SP_prediction <- super_learner(RF_prediction, SVM_prediction, XGB_prediction, Weights)
SP_results <- confusionMatrix(attrition_test$Attrition, SP_prediction)
SP_results <- confusionMatrix(attrition_test$Attrition, SP_prediction)
SP_results
# Problem 2
#2.1
#RF
library(vip)
set.seed(1)
library(randomForest)
data_train_no_na = na.omit(data_train)
data_train_no_na$V16 = as.factor(data_train_no_na$V16)
levels(data_train_no_na$V16) = make.names(levels(data_train_no_na$V16), unique=TRUE)
resample <- trainControl(method = "repeatedcv", number = 5, classProbs = TRUE)
hyper_grid_rf <- expand.grid(mtry = c(13, 15, 17, 20, 22, 25),
splitrule = c("extratrees"),
min.node.size = c(3, 5, 7, 9))
rf_fit <- train(V16 ~ .,
data = data_train_no_na,
method = "ranger",
trControl = resample,
tuneGrid = hyper_grid_rf,
metric = "ROC",
num.trees = 300)
ggplot(rf_fit)
transformed_train$V16_X. = as.factor(transformed_train$V16_X.)
levels(transformed_train$V16_X.) = make.names(levels(transformed_train$V16_X.))
transformed_test$V16_X. = as.factor(transformed_test$V16_X.)
levels(transformed_test$V16_X.) = make.names(levels(transformed_train$V16_X.))
fitControl_final <- trainControl(method = "none", classProbs = TRUE)
RF <- train(V16_X. ~ .,
data = transformed_train,
method = "ranger",
trControl = fitControl_final,
metric = "ROC",
tuneGrid = data.frame(mtry = 15,
min.node.size = 3,
splitrule = "extratrees"),
num.trees = 300,
importance = "impurity")
#XGBoost
hyper_grid_xg <- expand.grid(nrounds = c(25, 50, 75),
max_depth = c(4, 6, 8),
eta = c(0.05, 0.1, 0.2, 0.3),
min_child_weight = c(5, 10, 15),
subsample = c(0.4, 0.6),
gamma = 0,
colsample_bytree = 1)
xg_fit <- train(V16 ~ .,
data = data_train_no_na,
method = "xgbTree",
trControl = resample,
tuneGrid = hyper_grid_xg,
metric = "ROC",
verbosity = 0,
verbose = FALSE)
plot(xg_fit)
XGB <- train(V16_X. ~ .,
data = transformed_train,
method = "xgbTree",
verbose = FALSE,
verbosity = 0,
trControl = resample,
tuneGrid = hyper_grid_xg,
metric = "ROC")
#SVM
SVMGrid_Lin <- expand.grid(C = c(0.01, 0.1, 1, 10))
SVMGrid_Poly <- expand.grid(C = c(0.01, 0.1, 1, 10),
degree = c(2, 3),
scale = 1)
SVMGrid_RBF <- expand.grid (sigma = c(0.01, 0.1, 1, 10),
C = c(0.01, 0.1, 1, 10))
SVM_Linear <- train(V16_X. ~ .,
data = transformed_train,
method = "svmLinear",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_Lin,
metric = "ROC")
SVM_Poly <- train(V16_X. ~ .,
data = transformed_train,
method = "svmPoly",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_Poly,
metric = "ROC")
SVM_RBF <- train(V16_X. ~ .,
data = transformed_train,
method = "svmRadial",
trControl = resample,
verbose = FALSE,
tuneGrid = SVMGrid_RBF,
metric = "ROC")
resamps <- resamples(list(SVM_Linear = SVM_Linear,
SVM_Poly = SVM_Poly,
SVM_RBF = SVM_RBF))
summary(resamps)
bwplot(resamps, layout = c(3, 1))
#2.2
RF_pred_train <- predict(RF, newdata = transformed_train)
RF_train_results <- confusionMatrix(transformed_train$V16_X., RF_pred_train)
RF_Kappa <- RF_train_results$overall["Kappa"]
XGB_pred_train <- predict(XGB, newdata = transformed_train)
XGB_train_results <- confusionMatrix(transformed_train$V16_X., XGB_pred_train)
XGB_Kappa <- XGB_train_results$overall["Kappa"]
SVM_pred_train <- predict.train(SVM_Poly, newdata = transformed_train)
SVM_train_results <- confusionMatrix(transformed_train$V16_X., SVM_pred_train)
SVM_Kappa <- SVM_train_results$overall["Kappa"]
XGB_prediction <- predict(XGB, newdata = transformed_test, type = "prob")[,"X1"]
RF_prediction <- predict(RF, newdata = transformed_test, type = "prob")[,"X1"]
SVM_prediction <- predict(SVM_Poly, newdata = transformed_test, type = "prob")[,"X1"]
Weights <- c((RF_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(SVM_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(XGB_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2))
super_learner <- function(M1, M2, M3, W) {
weighted_average <- t(W*t(cbind(M1, M2, M3))) %>% apply(1, sum)
final_prediction <- ifelse(weighted_average > 0.5, "X1", "X0") %>% factor(levels = c("X1", "X0"))
return(final_prediction)
}
SP_prediction <- super_learner(RF_prediction, SVM_prediction, XGB_prediction, Weights)
SP_results <- confusionMatrix(transformed_train$V16_X., SP_prediction)
length(XGB_prediction)
length(SVM_prediction)
length(RF_prediction)
Weights
final_prediction <- ifelse(weighted_average > 0.5, "X0", "X1") %>% factor(levels = c("X0", "X1"))
super_learner <- function(M1, M2, M3, W) {
weighted_average <- t(W*t(cbind(M1, M2, M3))) %>% apply(1, sum)
final_prediction <- ifelse(weighted_average > 0.5, "X0", "X1") %>% factor(levels = c("X0", "X1"))
return(final_prediction)
}
SP_prediction <- super_learner(RF_prediction, SVM_prediction, XGB_prediction, Weights)
SP_results <- confusionMatrix(transformed_train$V16_X., SP_prediction)
SP_prediction
XGB_prediction
final_prediction <- ifelse(weighted_average > 0.5, "X1", "X0") %>% factor(levels = c("X1", "X0"))
final_prediction <- ifelse(weighted_average > 0.5, "X1", "X0") %>% factor(levels = c("X1", "X0"))
super_learner <- function(M1, M2, M3, W) {
weighted_average <- t(W*t(cbind(M1, M2, M3))) %>% apply(1, sum)
final_prediction <- ifelse(weighted_average > 0.5, "X1", "X0") %>% factor(levels = c("X1", "X0"))
return(final_prediction)
}
length(XGB_prediction)
length(SVM_prediction)
length(RF_prediction)
length(transformed_train$V16_X.)
SP_results <- confusionMatrix(transformed_test$V16_X., SP_prediction)
SP_results
confusionMatrix(transformed_test$V16_X., RF_prediction)
RF_train_results
XGB_train_results
SVM_train_results
summary(resamps)
bwplot(resamps, layout = c(3, 1))
SVM_pred_train <- predict.train(SVM_RBF, newdata = transformed_train)
RF_pred_train <- predict(RF, newdata = transformed_train)
RF_train_results <- confusionMatrix(transformed_train$V16_X., RF_pred_train)
RF_Kappa <- RF_train_results$overall["Kappa"]
XGB_pred_train <- predict(XGB, newdata = transformed_train)
XGB_train_results <- confusionMatrix(transformed_train$V16_X., XGB_pred_train)
XGB_Kappa <- XGB_train_results$overall["Kappa"]
SVM_pred_train <- predict.train(SVM_RBF, newdata = transformed_train)
SVM_train_results <- confusionMatrix(transformed_train$V16_X., SVM_pred_train)
SVM_Kappa <- SVM_train_results$overall["Kappa"]
XGB_prediction <- predict(XGB, newdata = transformed_test, type = "prob")[,"X1"]
RF_prediction <- predict(RF, newdata = transformed_test, type = "prob")[,"X1"]
SVM_prediction <- predict(SVM_RBF, newdata = transformed_test, type = "prob")[,"X1"]
RF_train_results
XGB_train_results
SVM_train_results
RF_train_results
Weights <- c((RF_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(SVM_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2),
(XGB_Kappa)^2/sum((RF_Kappa)^2 + (SVM_Kappa)^2 + (XGB_Kappa)^2))
super_learner <- function(M1, M2, M3, W) {
weighted_average <- t(W*t(cbind(M1, M2, M3))) %>% apply(1, sum)
final_prediction <- ifelse(weighted_average > 0.5, "X0", "X1") %>% factor(levels = c("X0", "X1"))
return(final_prediction)
}
SP_prediction <- super_learner(RF_prediction, SVM_prediction, XGB_prediction, Weights)
SP_results <- confusionMatrix(transformed_test$V16_X., SP_prediction)
SP_results
bwplot(resamps, layout = c(3, 1))
SVM_train_results
SVM_pred_test<- predict.train(SVM_RBF, newdata = transformed_est)
SVM_test_results <- confusionMatrix(transformed_test$V16_X., SVM_pred_test)
SVM_pred_test<- predict.train(SVM_RBF, newdata = transformed_test)
SVM_test_results <- confusionMatrix(transformed_test$V16_X., SVM_pred_test)
SVM_test_results
RF_pred_test <- predict(RF, newdata = transformed_test)
RF_test_results
RF_test_results
RF_pred_test <- predict(RF, newdata = transformed_test)
RF_test_results <- confusionMatrix(transformed_test$V16_X., RF_pred_test)
XGB_pred_test <- predict(XGB, newdata = transformed_test)
XGB_test_results <- confusionMatrix(transformed_test$V16_X., XGB_pred_test)
SVM_pred_test<- predict.train(SVM_RBF, newdata = transformed_test)
SVM_test_results <- confusionMatrix(transformed_test$V16_X., SVM_pred_test)
RF_test_results
SVM_test_results
XGB_test_results
RF_test_results
set.seed(1)
RF_test_results
XGB_test_results
SVM_test_results
bwplot(resamps, layout = c(3, 1))
library(ggplot2)
library(caret)
library(tidymodels)
library(tidyverse)
library(SmartEDA)
library(gplots)
cc_fraud = read.csv("application_data.csv")
summary(cc_fraud)
source("~/Final Project Data Exploration (Spring 2024).R", echo=TRUE)
savehistory("~/Final Project Data Exploration (Spring 2024).Rhistory")
